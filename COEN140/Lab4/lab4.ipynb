{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51001242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: COEN 140 Lab Machine Learning/Data Mining\n",
    "# Name: Matthew Davenport\n",
    "# Date: 9/25/2022\n",
    "# Title: Lab 4 – Iris classifier LDA and QDA without python libraries\n",
    "# Description: This program will perform clssifications\n",
    "#           on iris datasets based on the sepal\n",
    "#           lengths/widths and petal lengths/widths and \n",
    "#           classify them as Setosa, Versicolour, or Virginica\n",
    "#           without using python ML libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "ROWS = 150\n",
    "COLUMNS = 5\n",
    "CLASSIFICATIONS = 3\n",
    "FEATURES = ['sepal length','sepal width', 'pedal length', 'pedal width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa15214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing of proper reading of data (provided)\n",
    "def test_dataset(data):\n",
    "    if len(data) != 150:\n",
    "        return False\n",
    "    for row in data:\n",
    "        if len(row) != 5:\n",
    "            return False\n",
    "        for column in row[:-1]:\n",
    "            if type(column) != np.float64:\n",
    "                return False\n",
    "            \n",
    "        if type(row[-1]) != str:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8bea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file and convert the contents to the proper types and return list of lists\n",
    "def read_file(): \n",
    "    data = [[] for x in range(ROWS)]                 # initialize empty list of lists length 150\n",
    "    file = open('C:/Users/daven/COEN140/Lab4/test_dataset.txt', 'r')            # open file as read\n",
    "    contents = [line.split() for line in file]      # put contents of file into list of lists of characters\n",
    "    \n",
    "    #iterate through contents stopping at each , in the list of characters to convert the first 4 elements into \n",
    "    #           np.float64 nd the last into a string to be loaded into data\n",
    "    for row in range(len(contents)):                # iterate through contents\n",
    "        i = 0\n",
    "        for s in contents[row][0].split(\",\"):       # usingn , as delimiter\n",
    "            if i == (COLUMNS - 1):                              # at the last element just append as string\n",
    "                data[row].append(s)\n",
    "                break\n",
    "            i += 1\n",
    "            data[row].append(np.float64(s))         # append into data[row] the number converted to np.float64\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a1e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the actual classifications compared to our predictions for QDA and LDA\n",
    "# returns the percent error of predictions\n",
    "def classification_compare(predicted, actuals):\n",
    "    length = len(actuals)\n",
    "    correct_predictions = 0\n",
    "    for i in range(length):\n",
    "        if predicted[i] == actuals[i]:\n",
    "            correct_predictions += 1\n",
    "        else:\n",
    "            print(\"\\nIncorrect prediction at index \" + str(i))\n",
    "            print(\"Predicted: \" + predicted[i])\n",
    "            print(\"Actual: \", actuals[i])\n",
    "        \n",
    "    return 100 - correct_predictions/length * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89fad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_means(category): \n",
    "    means = []\n",
    "    for i in range(4): \n",
    "        temp_mean = 0\n",
    "        for j in range(40):\n",
    "            temp_mean += category[j][i]\n",
    "        temp_mean = temp_mean/40\n",
    "        means.append(temp_mean)\n",
    "    return means\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ca387cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(category, means):\n",
    "    variances = []\n",
    "    for i in range(4):\n",
    "        new_arr = np.array([observation[i] for observation in category])\n",
    "        variances.append(np.var(new_arr))\n",
    "        \n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb1d363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a matrix X of data representing all the different categories\n",
    "#      a row vector of means for these categories means\n",
    "#      and covariance matrix cov, compute probability using multivariate gaussian pdf.\n",
    "def multivariate_gauss_pdf(X, means, cov):\n",
    "    n = len(means)\n",
    "    X = X-np.array(means).T\n",
    "    return 1/((2*np.pi)**(n/2)*np.linalg.det(cov)**(0.5))*np.exp(-0.5*np.sum(X.dot(np.linalg.pinv(cov))*X,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67182975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "120\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Testing contentes of file converted successfully \n",
    "data = read_file()\n",
    "print(test_dataset(data))\n",
    "\n",
    "# split into training and testing lists \n",
    "training = data[:40:] + data[50:90:] + data[100:140:]\n",
    "testing = data[40:50:] + data[90:100:] + data[140:150:]\n",
    "\n",
    "# ensure proper length for training and testing items\n",
    "print(len(training))\n",
    "print(len(testing))\n",
    "\n",
    "# using np array to better manipulate columns of data\n",
    "training_array = np.array(training)\n",
    "testing_array = np.array(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58584ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays split sucessfully? True\n"
     ]
    }
   ],
   "source": [
    "# separation of X and y and testing/training\n",
    "# splitting of arrays into arrays by classification of flower\n",
    "# convert X from strings to floats using numpy\n",
    "x_training = training_array[:,0:4].astype(np.float64)\n",
    "x_testing = testing_array[:,0:4].astype(np.float64)\n",
    "y_testing = testing_array[:,4]\n",
    "y_training = training_array[:,4]\n",
    "\n",
    "# splitting of arrays based on classification\n",
    "setosa_training = x_training[:40]\n",
    "versicolor_training = x_training[40:80]\n",
    "virginica_training = x_training[80:120]\n",
    "\n",
    "# check arrays were split correctly \n",
    "print(\"Arrays split sucessfully? \" + \n",
    "      str(np.allclose(np.concatenate((setosa_training, np.concatenate((versicolor_training, virginica_training)))),x_training)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda924ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13112179 0.09897436 0.01298077 0.01362179]\n",
      " [0.09897436 0.13271795 0.00205128 0.0145641 ]\n",
      " [0.01298077 0.00205128 0.02958333 0.00458333]\n",
      " [0.01362179 0.0145641  0.00458333 0.00994231]]\n",
      "\n",
      "[[0.27374359 0.08661538 0.17212821 0.05230769]\n",
      " [0.08661538 0.11087179 0.08087179 0.04538462]\n",
      " [0.17212821 0.08087179 0.20353205 0.07371795]\n",
      " [0.05230769 0.04538462 0.07371795 0.04307692]]\n",
      "\n",
      "[[0.46794231 0.11041026 0.35777564 0.05125641]\n",
      " [0.11041026 0.11323077 0.08107692 0.04625641]\n",
      " [0.35777564 0.08107692 0.34532692 0.05930769]\n",
      " [0.05125641 0.04625641 0.05930769 0.07425641]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# computing means for each cateory\n",
    "setosa_means = category_means(setosa_training)\n",
    "versicolor_means = category_means(versicolor_training)\n",
    "virginica_means = category_means(virginica_training)\n",
    "# print(setosa_means)\n",
    "# print(versicolor_means)\n",
    "# print(virginica_means)\n",
    "\n",
    "setosa_cov = np.cov(setosa_training, rowvar=False)\n",
    "versicolor_cov = np.cov(versicolor_training, rowvar=False)\n",
    "virginica_cov = np.cov(virginica_training, rowvar=False)\n",
    "average_cov = (setosa_cov + versicolor_cov + virginica_cov) / 3\n",
    "print(setosa_cov, end=\"\\n\\n\")\n",
    "print(versicolor_cov, end=\"\\n\\n\")\n",
    "print(virginica_cov, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c410706a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.63344873e+00 7.04224498e-04 1.27971298e+00 4.45604179e-01\n",
      " 5.59282137e-01 8.07876839e-01 9.57493988e-01 1.91769018e+00\n",
      " 2.20760576e+00 3.21401964e+00 2.33083228e-22 5.96313501e-21\n",
      " 3.38968253e-17 1.38160095e-14 6.31206388e-20 5.24117072e-17\n",
      " 2.72283051e-18 1.78834668e-17 2.93847350e-12 5.88710827e-18\n",
      " 4.52864493e-44 2.36542141e-37 1.50162818e-36 5.66795327e-44\n",
      " 1.57319738e-45 2.56012607e-39 1.94491872e-35 1.27809885e-33\n",
      " 9.26632376e-40 2.68549403e-32]\n",
      "\n",
      "[1.26937594e-20 3.75317994e-14 4.40682304e-18 1.44453296e-15\n",
      " 1.92864387e-17 4.16951788e-16 5.80686606e-22 1.23959537e-17\n",
      " 2.36391665e-22 2.58473874e-19 3.89887158e-01 1.75564196e+00\n",
      " 2.40223529e+00 1.90704099e-01 2.21969831e+00 5.70519926e-01\n",
      " 1.80935567e+00 2.84554859e+00 2.23026776e-02 2.72580794e+00\n",
      " 1.12026444e-06 5.62096625e-06 2.46006163e-03 4.69943472e-06\n",
      " 1.27991079e-07 9.17879447e-06 3.70404092e-03 1.09290233e-02\n",
      " 7.94671739e-06 1.36184511e-02]\n",
      "\n",
      "[3.97231037e-39 2.02404342e-30 7.49657409e-36 1.81825261e-31\n",
      " 6.66317141e-34 2.36783466e-33 1.68536433e-40 2.32562994e-35\n",
      " 2.11206983e-41 9.27853264e-38 5.55095408e-04 5.56642746e-03\n",
      " 5.38695833e-05 5.73965471e-08 1.19359187e-03 2.72928344e-05\n",
      " 3.89602251e-04 2.42398839e-04 8.71228549e-10 3.57894070e-04\n",
      " 1.64818147e-01 2.48345149e-03 1.12642203e+00 1.13782313e+00\n",
      " 7.83387336e-02 2.33750100e-02 2.49471776e-01 1.42887563e+00\n",
      " 1.69386543e-01 5.54751884e-01]\n",
      "\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "LDA testing error: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# LDA classification for test data\n",
    "\n",
    "#compute probabilities of each entry belonging to category of flower for testing group\n",
    "set_prob_test = multivariate_gauss_pdf(x_testing, setosa_means, average_cov )\n",
    "vers_prob_test = multivariate_gauss_pdf(x_testing, versicolor_means, average_cov )\n",
    "virg_prob_test = multivariate_gauss_pdf(x_testing, virginica_means, average_cov )\n",
    "print(set_prob_test, end=\"\\n\\n\")\n",
    "print(vers_prob_test, end=\"\\n\\n\")\n",
    "print(virg_prob_test, end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "lda_test_class = []\n",
    "for i in range(30): \n",
    "    if set_prob_test[i] > vers_prob_test[i] and set_prob_test[i] > virg_prob_test[i]:\n",
    "        lda_test_class.append('Iris-setosa')\n",
    "    elif vers_prob_test[i] > set_prob_test[i] and vers_prob_test[i] > virg_prob_test[i]:\n",
    "        lda_test_class.append('Iris-versicolor')\n",
    "    elif virg_prob_test[i] > set_prob_test[i] and virg_prob_test[i] > vers_prob_test[i]:\n",
    "        lda_test_class.append('Iris-virginica')\n",
    "    \n",
    "print(lda_test_class == y_testing)    ## should all be true\n",
    "incorrect = (lda_test_class == y_testing).tolist().count(False)\n",
    "print(\"LDA testing error: \" + str(incorrect/(len(lda_test_class)) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2439995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.81177785e+000 1.81048629e-003 2.27890748e+000 5.59770776e-003\n",
      " 1.00272575e-001 3.10718374e+000 3.02575674e+000 8.97886808e+000\n",
      " 1.10596611e+001 1.61224185e+001 1.25995675e-075 2.35307034e-088\n",
      " 6.17990203e-062 1.21308375e-037 1.94845153e-071 1.03616745e-065\n",
      " 4.92882422e-070 4.70777807e-074 4.25477587e-034 2.42969159e-067\n",
      " 2.20243455e-197 2.22033914e-167 8.96771811e-140 7.88258040e-203\n",
      " 4.69068926e-209 4.04541604e-172 4.08462993e-138 6.88871015e-148\n",
      " 2.77756948e-177 1.10142004e-130]\n",
      "\n",
      "[5.88902311e-23 1.73532119e-12 1.70664995e-19 3.58520997e-18\n",
      " 6.31867093e-21 2.01425700e-16 4.57657405e-26 5.79339655e-19\n",
      " 1.12468803e-25 9.24900533e-21 2.40751868e-01 2.44508165e+00\n",
      " 3.92526536e+00 3.67453462e-01 3.33068754e+00 4.88100376e-01\n",
      " 2.71070381e+00 3.77762450e+00 9.19610454e-03 3.97986533e+00\n",
      " 1.65374215e-08 1.09930077e-09 2.04944426e-03 1.00979403e-05\n",
      " 2.91398336e-09 6.38674374e-09 2.35510388e-04 4.84677519e-03\n",
      " 6.35435188e-06 7.32798211e-02]\n",
      "\n",
      "[9.35547567e-36 4.79357840e-26 1.93466684e-29 6.64854132e-29\n",
      " 8.39767713e-30 2.61432439e-29 8.55244329e-36 1.29804288e-29\n",
      " 4.38094192e-38 1.06527756e-33 1.31807440e-02 1.83458137e-02\n",
      " 3.08060272e-04 5.59130953e-06 9.94926107e-03 6.35497100e-04\n",
      " 3.38968338e-03 5.22602840e-04 3.95785623e-08 2.33053061e-03\n",
      " 4.55493468e-01 5.74628822e-03 9.08514382e-01 1.02991327e+00\n",
      " 3.00237797e-01 6.81660862e-02 1.95355696e-01 9.51533704e-01\n",
      " 2.59190286e-01 5.89810146e-01]\n",
      "\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n",
      "QDA testing error: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# QDA classification for test data\n",
    "            \n",
    "# compute probabilities of each entry belonging to category of flower for testing group\n",
    "set_prob_test = multivariate_gauss_pdf(x_testing, setosa_means, setosa_cov)\n",
    "vers_prob_test = multivariate_gauss_pdf(x_testing, versicolor_means, versicolor_cov)\n",
    "virg_prob_test = multivariate_gauss_pdf(x_testing, virginica_means, virginica_cov)\n",
    "print(set_prob_test, end=\"\\n\\n\")\n",
    "print(vers_prob_test, end=\"\\n\\n\")\n",
    "print(virg_prob_test, end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "qda_test_class = []\n",
    "for i in range(30): \n",
    "    if set_prob_test[i] > vers_prob_test[i] and set_prob_test[i] > virg_prob_test[i]:\n",
    "        qda_test_class.append('Iris-setosa')\n",
    "    elif vers_prob_test[i] > set_prob_test[i] and vers_prob_test[i] > virg_prob_test[i]:\n",
    "        qda_test_class.append('Iris-versicolor')\n",
    "    elif virg_prob_test[i] > set_prob_test[i] and virg_prob_test[i] > vers_prob_test[i]:\n",
    "        qda_test_class.append('Iris-virginica')\n",
    "    \n",
    "print(qda_test_class == y_testing)    ## should all be true\n",
    "incorrect = (qda_test_class == y_testing).tolist().count(False)\n",
    "print(\"QDA testing error: \" + str(incorrect/(len(qda_test_class)) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "684bba6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True]\n",
      "LDA training error: 2.5%\n"
     ]
    }
   ],
   "source": [
    "# computing LDA classifications for the training data\n",
    "# probabilites\n",
    "set_prob_train = multivariate_gauss_pdf(x_training, setosa_means, average_cov)\n",
    "vers_prob_train = multivariate_gauss_pdf(x_training, versicolor_means, average_cov)\n",
    "virg_prob_train = multivariate_gauss_pdf(x_training, virginica_means, average_cov)\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "lda_train_class = []\n",
    "for i in range(120): \n",
    "    if set_prob_train[i] > vers_prob_train[i] and set_prob_train[i] > virg_prob_train[i]:\n",
    "        lda_train_class.append('Iris-setosa')\n",
    "    elif vers_prob_train[i] > set_prob_train[i] and vers_prob_train[i] > virg_prob_train[i]:\n",
    "        lda_train_class.append('Iris-versicolor')\n",
    "    elif virg_prob_train[i] > set_prob_train[i] and virg_prob_train[i] > vers_prob_train[i]:\n",
    "        lda_train_class.append('Iris-virginica')\n",
    "    \n",
    "print(lda_train_class == y_training)    \n",
    "incorrect = (lda_train_class == y_training).tolist().count(False)\n",
    "error = incorrect/len(lda_train_class) * 100\n",
    "print(\"LDA training error: \" + str(error) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9bb9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True]\n",
      "QDA training error: 1.6666666666666667%\n",
      "Time elapsed for QDA analysis: 2.563953399658203 msec\n"
     ]
    }
   ],
   "source": [
    "# computing QDA classifications for the training data\n",
    "start = time.time()\n",
    "# probabilites\n",
    "set_prob_train = multivariate_gauss_pdf(x_training, setosa_means, setosa_cov)\n",
    "vers_prob_train = multivariate_gauss_pdf(x_training, versicolor_means, versicolor_cov)\n",
    "virg_prob_train = multivariate_gauss_pdf(x_training, virginica_means, virginica_cov)\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "qda_train_class = []\n",
    "for i in range(120): \n",
    "    if set_prob_train[i] > vers_prob_train[i] and set_prob_train[i] > virg_prob_train[i]:\n",
    "        qda_train_class.append('Iris-setosa')\n",
    "    elif vers_prob_train[i] > set_prob_train[i] and vers_prob_train[i] > virg_prob_train[i]:\n",
    "        qda_train_class.append('Iris-versicolor')\n",
    "    elif virg_prob_train[i] > set_prob_train[i] and virg_prob_train[i] > vers_prob_train[i]:\n",
    "        qda_train_class.append('Iris-virginica')\n",
    "    \n",
    "print(qda_train_class == y_training)    \n",
    "incorrect = (qda_train_class == y_training).tolist().count(False)\n",
    "error = incorrect/len(qda_train_class) * 100\n",
    "print(\"QDA training error: \" + str(error) + \"%\")\n",
    "end = time.time()\n",
    "time_elapsed = end - start\n",
    "print(\"Time elapsed for QDA analysis: \" + str(time_elapsed * 1000) + \" msec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b1f9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setosa classification errors using LDA: 0.0%\n",
      "Versicolor classification errors using LDA: 5.0%\n",
      "Virginica classification errors using LDA: 2.5%\n"
     ]
    }
   ],
   "source": [
    "# 4. Is there any class linearly separable from other classes? Explain your answer based on \n",
    "# your experiments.\n",
    "\n",
    "# computing LDA classifications for the training data\n",
    "\n",
    "# probabilites\n",
    "set_prob_train = multivariate_gauss_pdf(x_training, setosa_means, average_cov)\n",
    "vers_prob_train = multivariate_gauss_pdf(x_training, versicolor_means, average_cov)\n",
    "virg_prob_train = multivariate_gauss_pdf(x_training, virginica_means, average_cov)\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "lda_train_class = []\n",
    "for i in range(120): \n",
    "    if set_prob_train[i] > vers_prob_train[i] and set_prob_train[i] > virg_prob_train[i]:\n",
    "        lda_train_class.append('Iris-setosa')\n",
    "    elif vers_prob_train[i] > set_prob_train[i] and vers_prob_train[i] > virg_prob_train[i]:\n",
    "        lda_train_class.append('Iris-versicolor')\n",
    "    elif virg_prob_train[i] > set_prob_train[i] and virg_prob_train[i] > vers_prob_train[i]:\n",
    "        lda_train_class.append('Iris-virginica')\n",
    "    \n",
    "prediction_results = (lda_train_class == y_training)\n",
    "setosa_results = prediction_results[:40]\n",
    "versicolor_results = prediction_results[40:80]\n",
    "virginica_results = prediction_results[80:120]\n",
    "\n",
    "setosa_incorrect = setosa_results.tolist().count(False)\n",
    "versicolor_incorrect = versicolor_results.tolist().count(False)\n",
    "virginica_incorrect = virginica_results.tolist().count(False)\n",
    "\n",
    "setosa_error = setosa_incorrect/40 * 100\n",
    "versicolor_error = versicolor_incorrect/40 * 100\n",
    "virginica_error = virginica_incorrect/40 * 100\n",
    "\n",
    "print(\"Setosa classification errors using LDA: \" + str(setosa_error) + \"%\")\n",
    "print(\"Versicolor classification errors using LDA: \" + str(versicolor_error) + \"%\")\n",
    "print(\"Virginica classification errors using LDA: \" + str(virginica_error) + \"%\")\n",
    "\n",
    "############################################ OBSERVATIONS #####################################################\n",
    "# The only class linearly separable from other classes is the 'Iris-Setosa' class,\n",
    "# as there were no classification errors when using LDA to classify the flower. \n",
    "# Versicolor and Virginica both had erros when classifying using LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9978ee30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True False  True  True  True  True  True  True]\n",
      "QDA training error: 4.166666666666666%\n",
      "Time elapsed for QDA analysis: 1.6934871673583984 msec\n"
     ]
    }
   ],
   "source": [
    "# 5. Assume the features are independent, i.e., ∑ is a diagonal matrix. Repeat Question 3, and \n",
    "# report your results. Also, please report the training time of this method and the original \n",
    "# QDA that you implemented in Question 3. \n",
    " \n",
    "# first create diagonal covariances\n",
    "set_diag = np.zeros((4,4))\n",
    "vers_diag = np.zeros((4,4))\n",
    "virg_diag = np.zeros((4,4))\n",
    "for row in range(setosa_cov.shape[0]): \n",
    "    for col in range(setosa_cov.shape[1]): \n",
    "        if row == col:\n",
    "            set_diag[row][col] = setosa_cov[row][col]\n",
    "            vers_diag[row][col] = versicolor_cov[row][col]\n",
    "            virg_diag[row][col] = virginica_cov[row][col]\n",
    "            \n",
    "#QDA assuming independence (diagonal matrices)\n",
    "start = time.time()\n",
    "# probabilites\n",
    "set_prob_train = multivariate_gauss_pdf(x_training, setosa_means, set_diag)\n",
    "vers_prob_train = multivariate_gauss_pdf(x_training, versicolor_means, vers_diag)\n",
    "virg_prob_train = multivariate_gauss_pdf(x_training, virginica_means, virg_diag)\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "qda_train_class = []\n",
    "for i in range(120): \n",
    "    if set_prob_train[i] > vers_prob_train[i] and set_prob_train[i] > virg_prob_train[i]:\n",
    "        qda_train_class.append('Iris-setosa')\n",
    "    elif vers_prob_train[i] > set_prob_train[i] and vers_prob_train[i] > virg_prob_train[i]:\n",
    "        qda_train_class.append('Iris-versicolor')\n",
    "    elif virg_prob_train[i] > set_prob_train[i] and virg_prob_train[i] > vers_prob_train[i]:\n",
    "        qda_train_class.append('Iris-virginica')\n",
    "    \n",
    "print(qda_train_class == y_training)    \n",
    "incorrect = (qda_train_class == y_training).tolist().count(False)\n",
    "error = incorrect/len(qda_train_class) * 100\n",
    "print(\"QDA training error: \" + str(error) + \"%\")\n",
    "end = time.time()\n",
    "time_elapsed = end - start\n",
    "print(\"Time elapsed for QDA analysis: \" + str(time_elapsed * 1000) + \" msec\")\n",
    "\n",
    "############################################# OBSERVATION #######################################################\n",
    "# Although only marginally faster, with a large increase in data, the time difference would become more apparent,\n",
    "# as the diagonal matrix did help with the efficiency of the QDA analysis. This could also have been more apparent\n",
    "# had the calculations of means, covariances and other calculations done separate had been more concise. \n",
    "# The accuracy was still better than LDA with diagonal matrices and QDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8550f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
