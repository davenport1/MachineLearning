{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e523f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class: COEN 140 Lab Machine Learning/Data Mining\n",
    "# Name: Matthew Davenport\n",
    "# Date: 9/25/2022\n",
    "# Title: Lab 4 â€“ Iris classifier LDA and QDA without python libraries\n",
    "# Description: This program will perform clssifications\n",
    "#           on iris datasets based on the sepal\n",
    "#           lengths/widths and petal lengths/widths and \n",
    "#           classify them as Setosa, Versicolour, or Virginica\n",
    "#           without using python ML libraries\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "ROWS = 150\n",
    "COLUMNS = 5\n",
    "CLASSIFICATIONS = 3\n",
    "FEATURES = ['sepal length','sepal width', 'pedal length', 'pedal width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31828924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing of proper reading of data (provided)\n",
    "def test_dataset(data):\n",
    "    if len(data) != 150:\n",
    "        return False\n",
    "    for row in data:\n",
    "        if len(row) != 5:\n",
    "            return False\n",
    "        for column in row[:-1]:\n",
    "            if type(column) != np.float64:\n",
    "                return False\n",
    "            \n",
    "        if type(row[-1]) != str:\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85cac987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file and convert the contents to the proper types and return list of lists\n",
    "def read_file(): \n",
    "    data = [[] for x in range(ROWS)]                 # initialize empty list of lists length 150\n",
    "    file = open('C:/Users/daven/COEN140/Lab3/test_dataset.txt', 'r')            # open file as read\n",
    "    contents = [line.split() for line in file]      # put contents of file into list of lists of characters\n",
    "    \n",
    "    #iterate through contents stopping at each , in the list of characters to convert the first 4 elements into \n",
    "    #           np.float64 nd the last into a string to be loaded into data\n",
    "    for row in range(len(contents)):                # iterate through contents\n",
    "        i = 0\n",
    "        for s in contents[row][0].split(\",\"):       # usingn , as delimiter\n",
    "            if i == (COLUMNS - 1):                              # at the last element just append as string\n",
    "                data[row].append(s)\n",
    "                break\n",
    "            i += 1\n",
    "            data[row].append(np.float64(s))         # append into data[row] the number converted to np.float64\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3cd73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the actual classifications compared to our predictions for QDA and LDA\n",
    "# returns the percent error of predictions\n",
    "def classification_compare(predicted, actuals):\n",
    "    length = len(actuals)\n",
    "    correct_predictions = 0\n",
    "    for i in range(length):\n",
    "        if predicted[i] == actuals[i]:\n",
    "            correct_predictions += 1\n",
    "        else:\n",
    "            print(\"\\nIncorrect prediction at index \" + str(i))\n",
    "            print(\"Predicted: \" + predicted[i])\n",
    "            print(\"Actual: \", actuals[i])\n",
    "        \n",
    "    return 100 - correct_predictions/length * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32758079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_means(category): \n",
    "    means = []\n",
    "    for i in range(4): \n",
    "        temp_mean = 0\n",
    "        for j in range(40):\n",
    "            temp_mean += category[j][i]\n",
    "        temp_mean = temp_mean/40\n",
    "        means.append(temp_mean)\n",
    "    return means\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97e85980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(category, means):\n",
    "    variances = []\n",
    "    for i in range(4):\n",
    "        new_arr = np.array([observation[i] for observation in category])\n",
    "        variances.append(np.var(new_arr))\n",
    "        \n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9530b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_pdf(X, u, var):\n",
    "    prob_density = (np.pi*var) * np.exp(-0.5*((X-u)/var)**2)\n",
    "    return prob_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11898aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "120\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# Testing contentes of file converted successfully \n",
    "data = read_file()\n",
    "print(test_dataset(data))\n",
    "\n",
    "# split into training and testing lists \n",
    "training = data[:40:] + data[50:90:] + data[100:140:]\n",
    "testing = data[40:50:] + data[90:100:] + data[140:150:]\n",
    "\n",
    "# ensure proper length for training and testing items\n",
    "print(len(training))\n",
    "print(len(testing))\n",
    "\n",
    "# using np array to better manipulate columns of data\n",
    "training_array = np.array(training)\n",
    "testing_array = np.array(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66834072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays split sucessfully? True\n"
     ]
    }
   ],
   "source": [
    "# separation of X and y and testing/training\n",
    "# splitting of arrays into arrays by classification of flower\n",
    "# convert X from strings to floats using numpy\n",
    "x_training = training_array[:,0:4].astype(np.float64)\n",
    "x_testing = testing_array[:,0:4].astype(np.float64)\n",
    "y_testing = testing_array[:,4]\n",
    "y_training = training_array[:,4]\n",
    "\n",
    "# splitting of arrays based on classification\n",
    "setosa_training = x_training[:40]\n",
    "versicolor_training = x_training[40:80]\n",
    "virginica_training = x_training[80:120]\n",
    "\n",
    "# check arrays were split correctly \n",
    "print(\"Arrays split sucessfully? \" + \n",
    "      str(np.allclose(np.concatenate((setosa_training, np.concatenate((versicolor_training, virginica_training)))),x_training)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c30c93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13112179 0.09897436 0.01298077 0.01362179]\n",
      " [0.09897436 0.13271795 0.00205128 0.0145641 ]\n",
      " [0.01298077 0.00205128 0.02958333 0.00458333]\n",
      " [0.01362179 0.0145641  0.00458333 0.00994231]]\n",
      "\n",
      "[[0.27374359 0.08661538 0.17212821 0.05230769]\n",
      " [0.08661538 0.11087179 0.08087179 0.04538462]\n",
      " [0.17212821 0.08087179 0.20353205 0.07371795]\n",
      " [0.05230769 0.04538462 0.07371795 0.04307692]]\n",
      "\n",
      "[[0.46794231 0.11041026 0.35777564 0.05125641]\n",
      " [0.11041026 0.11323077 0.08107692 0.04625641]\n",
      " [0.35777564 0.08107692 0.34532692 0.05930769]\n",
      " [0.05125641 0.04625641 0.05930769 0.07425641]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# computing means for each cateory\n",
    "setosa_means = category_means(setosa_training)\n",
    "versicolor_means = category_means(versicolor_training)\n",
    "virginica_means = category_means(virginica_training)\n",
    "# print(setosa_means)\n",
    "# print(versicolor_means)\n",
    "# print(virginica_means)\n",
    "\n",
    "# # variances\n",
    "# setosa_variances = variance(setosa_training, setosa_means)\n",
    "# versicolor_variances = variance(versicolor_training, versicolor_means)\n",
    "# virginica_variances = variance(virginica_training, virginica_means)\n",
    "# print(setosa_variances)\n",
    "# print(versicolor_variances)\n",
    "# print(virginica_variances)\n",
    "\n",
    "# covariances for each classification\n",
    "setosa_cov = np.cov(setosa_training, rowvar=False)\n",
    "versicolor_cov = np.cov(versicolor_training, rowvar=False)\n",
    "virginica_cov = np.cov(virginica_training, rowvar=False)\n",
    "print(setosa_cov, end=\"\\n\\n\")\n",
    "print(versicolor_cov, end=\"\\n\\n\")\n",
    "print(virginica_cov, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "982096c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.81177785e+000 1.81048629e-003 2.27890748e+000 5.59770776e-003\n",
      " 1.00272575e-001 3.10718374e+000 3.02575674e+000 8.97886808e+000\n",
      " 1.10596611e+001 1.61224185e+001 1.25995675e-075 2.35307034e-088\n",
      " 6.17990203e-062 1.21308375e-037 1.94845153e-071 1.03616745e-065\n",
      " 4.92882422e-070 4.70777807e-074 4.25477587e-034 2.42969159e-067\n",
      " 2.20243455e-197 2.22033914e-167 8.96771811e-140 7.88258040e-203\n",
      " 4.69068926e-209 4.04541604e-172 4.08462993e-138 6.88871015e-148\n",
      " 2.77756948e-177 1.10142004e-130]\n",
      "\n",
      "[5.88902311e-23 1.73532119e-12 1.70664995e-19 3.58520997e-18\n",
      " 6.31867093e-21 2.01425700e-16 4.57657405e-26 5.79339655e-19\n",
      " 1.12468803e-25 9.24900533e-21 2.40751868e-01 2.44508165e+00\n",
      " 3.92526536e+00 3.67453462e-01 3.33068754e+00 4.88100376e-01\n",
      " 2.71070381e+00 3.77762450e+00 9.19610454e-03 3.97986533e+00\n",
      " 1.65374215e-08 1.09930077e-09 2.04944426e-03 1.00979403e-05\n",
      " 2.91398336e-09 6.38674374e-09 2.35510388e-04 4.84677519e-03\n",
      " 6.35435188e-06 7.32798211e-02]\n",
      "\n",
      "[9.35547567e-36 4.79357840e-26 1.93466684e-29 6.64854132e-29\n",
      " 8.39767713e-30 2.61432439e-29 8.55244329e-36 1.29804288e-29\n",
      " 4.38094192e-38 1.06527756e-33 1.31807440e-02 1.83458137e-02\n",
      " 3.08060272e-04 5.59130953e-06 9.94926107e-03 6.35497100e-04\n",
      " 3.38968338e-03 5.22602840e-04 3.95785623e-08 2.33053061e-03\n",
      " 4.55493468e-01 5.74628822e-03 9.08514382e-01 1.02991327e+00\n",
      " 3.00237797e-01 6.81660862e-02 1.95355696e-01 9.51533704e-01\n",
      " 2.59190286e-01 5.89810146e-01]\n",
      "\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# QDA classification for test data\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# compute probabilities of each entry belonging to category of flower for testing group\n",
    "set_prob_test = multivariate_normal.pdf(x_testing, setosa_means, setosa_cov)\n",
    "vers_prob_test = multivariate_normal.pdf(x_testing, versicolor_means, versicolor_cov)\n",
    "virg_prob_test = multivariate_normal.pdf(x_testing, virginica_means, virginica_cov)\n",
    "print(set_prob_test, end=\"\\n\\n\")\n",
    "print(vers_prob_test, end=\"\\n\\n\")\n",
    "print(virg_prob_test, end=\"\\n\\n\")\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "qda_test_class = []\n",
    "for i in range(30): \n",
    "    if set_prob_test[i] > vers_prob_test[i] and set_prob_test[i] > virg_prob_test[i]:\n",
    "        qda_test_class.append('Iris-setosa')\n",
    "    elif vers_prob_test[i] > set_prob_test[i] and vers_prob_test[i] > virg_prob_test[i]:\n",
    "        qda_test_class.append('Iris-versicolor')\n",
    "    elif virg_prob_test[i] > set_prob_test[i] and virg_prob_test[i] > vers_prob_test[i]:\n",
    "        qda_test_class.append('Iris-virginica')\n",
    "    \n",
    "print(qda_test_class == y_testing)    ## should all be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acad8584",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_prob_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m lda_test_class \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m): \n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mset_prob_test\u001b[49m \u001b[38;5;241m>\u001b[39m vers_prob_test \u001b[38;5;129;01mand\u001b[39;00m set_prob_test \u001b[38;5;241m>\u001b[39m virg_prob_test:\n\u001b[0;32m      4\u001b[0m         lda_test_class\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msetosa\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m vers_prob_test \u001b[38;5;241m>\u001b[39m set_prob_test \u001b[38;5;129;01mand\u001b[39;00m vers_prob_test \u001b[38;5;241m>\u001b[39m virg_prob_test:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'set_prob_test' is not defined"
     ]
    }
   ],
   "source": [
    "## print(f\"{100 * incorrect/total length:.2f}%\") printing percentges\n",
    "# computing QDA classifications for the training data\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# probabilites\n",
    "set_prob_train = multivariate_normal.pdf(x_training, setosa_means, setosa_cov)\n",
    "vers_prob_train = multivariate_normal.pdf(x_training, versicolor_means, versicolor_cov)\n",
    "virg_prob_train = multivariate_normal.pdf(x_training, virginica_means, virginica_cov)\n",
    "print(set_prob_train, end=\"\\n\\n\")\n",
    "print(vers_prob_train, end=\"\\n\\n\")\n",
    "print(virg_prob_train, end=\"\\n\\n\")\n",
    "\n",
    "# classify based on comparisons of probabilities that each belongs to a certain category\n",
    "qda_train_class = []\n",
    "for i in range(120): \n",
    "    if set_prob_train[i] > vers_prob_train[i] and set_prob_train[i] > virg_prob_train[i]:\n",
    "        qda_train_class.append('Iris-setosa')\n",
    "    elif vers_prob_train[i] > set_prob_train[i] and vers_prob_train[i] > virg_prob_train[i]:\n",
    "        qda_train_class.append('Iris-versicolor')\n",
    "    elif virg_prob_train[i] > set_prob_train[i] and virg_prob_train[i] > vers_prob_train[i]:\n",
    "        qda_train_class.append('Iris-virginica')\n",
    "    \n",
    "print(qda_train_class == y_testing)    ## should all be true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA classifier\n",
    "class LDA: \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def fit(X, y): \n",
    "        return 0\n",
    "    \n",
    "    def predict(X):\n",
    "        return 0\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
